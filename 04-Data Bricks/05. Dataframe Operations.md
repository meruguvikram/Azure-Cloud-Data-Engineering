# Dataframe Operations

# calculate totalsal of emp
``` python
from pyspark.sql.functions import col, when, expr
df=(spark.read.format("csv").option("header",True).load("dbfs:/FileStore/tables/b240303/emp-1.csv")
    .withColumn("COMM", when(col("COMM").isNull(), 0).otherwise(col("COMM")))
    .withColumn("Totalsal",expr("SAL+COMM"))
)
df.show()
```
## Word Count
1. upload the file `Cloud-Data-Engineering/labdata/sample.txt`
2. Copy DBFS path
3. observe contents of file
       ``` fs
       %fs head /FileStore/tables/sample.txt
       ```
4. Load file and observe data

``` pyspark
       df = (spark
      .read
      .format("text")
      .load("/FileStore/tables/sample.txt")
      .toDF("lines")
     ) 
```
     
```pysaprk
display(df)
```
5. Split into words

``` python
from pyspark.sql.functions import split
split_df = (
df.select(split("lines"," ").alias("words")))
```
```python
split_df.show()
```
``` python
split_df.printSchema()
```
6. get one word in each line

```python
from pyspark.sql.functions import explode
explode_df = split_df.select(explode("words").alias("word"))
```
``` python
display(explode_df)
```
``` python
explode_df.printSchema()
```
7. Aggregate data

``` python
agg_df = explode_df.groupBy("word").count()
display(agg_df)
```
8. Get top 5 records

``` python
from pyspark.sql.functions import desc
sorted_df = agg_df.orderBy(desc("count")).limit(5)
display(sorted_df)
```
9. 
## Explode Example 1
1. Observe Data

``` python
%fs head  /FileStore/tables/dec2022_data/input.json
```
2. Load into dataframe
``` python
input_df = (spark
            .read
            .format("json")
            .option("multiline", "true")
            .load("/FileStore/tables/dec2022_data/input.json"))
```
```python
display(input_df)
```
```python
input_df.printSchema()
```
```python
final_df = input_df.select("name", explode("values").alias("values"))
```
```python
display(final_df)
```

3. 
## Explode Example 2
1. observe data
``` python
%fs head  /FileStore/tables/dec2022_data/students_nested_json_data.json
```

2. Load Data
```python
stu_df = (spark
          .read
          .format("json")
          .option("multiline", "true")
          .load("/FileStore/tables/dec2022_data/students_nested_json_data.json"))
```
```python
display(stu_df)
```
3. print schema

``` python
stu_df.printSchema()
```
4. explode on array
```python
from pyspark.sql.functions import explode
explode_df = stu_df.select("name", explode("Education").alias("edu_exploded"))
```
```python
display(explode_df)
```
```python
explode_df.printSchema()
```
5. work with `*` 
```python
final_df = (explode_df.select("name", "edu_exploded.*"))
```
```python
display(final_df)
```
6. Observe Schema
```python
final_df.printSchema()
```
7. 
